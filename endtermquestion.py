# -*- coding: utf-8 -*-
"""ENDTERMQUESTION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vlG3TkzpUtqqmtHLA70-L4fOBsNjATPt
"""

# Data Preprocessing

import pandas as pd
import numpy as np
# We use train_test split to create train/test sets
from sklearn.model_selection import train_test_split

#LabelEncode converts text categories into integer codes
#StandardScaler standardizes numeric features to mean
from sklearn.preprocessing import LabelEncoder, StandardScaler

#Load the DATA
df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Lung_Cancer_dataset.csv")

#Show the shape and first rows to confirm the load and we get to see the column names
print("Dataset shape (rows, columns):", df.shape)
display(df.head())

# Select Features & Target
# Drop columns that donâ€™t help prediction (Name, Surname are just identifiers)
df = df.drop(columns=["Name", "Surname"], errors="ignore")

# Target is "Result"
TARGET = "Result"
y = df[TARGET]
X = df.drop(columns=[TARGET])

print("Features:", X.columns.tolist())
print("Target  :", TARGET)

# Missing Values, Encoding, Scaling
# Fill missing numeric values (if any) with median
for c in X.columns:
    if X[c].dtype != "object":
        X[c] = X[c].fillna(X[c].median())

# Encode target if not numeric already
if y.dtype == "object":
    y = LabelEncoder().fit_transform(y.astype(str))

# Standardize features (important before PCA)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

print("Scaled feature shape:", X_scaled.shape)

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y)

print("Train shapes:", X_train.shape, y_train.shape)
print("Test shapes :", X_test.shape, y_test.shape)

# Baseline Decision Tree Model

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

# Initialize the Decision Tree
dt = DecisionTreeClassifier(random_state=42)

# Train the model
dt.fit(X_train, y_train)

# Predict on test data
y_pred = dt.predict(X_test)

# ======================
# Evaluation
# ======================
print("Accuracy :", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, zero_division=0))
print("Recall   :", recall_score(y_test, y_pred, zero_division=0))
print("F1 Score :", f1_score(y_test, y_pred, zero_division=0))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred, zero_division=0))

#PCA + DECISION TREE


from sklearn.decomposition import PCA

# Apply PCA, keep 95% variance
pca = PCA(n_components=0.95)
X_pca = pca.fit_transform(X_scaled)

# Train-test split again (on reduced features)
X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(
    X_pca, y, test_size=0.2, random_state=42
)

# Retrain DT on reduced features
dt_pca = DecisionTreeClassifier(random_state=42)
dt_pca.fit(X_train_pca, y_train_pca)

# Predictions
y_pred_pca = dt_pca.predict(X_test_pca)

# Evaluate model
print("\nDecision Tree with PCA Performance:")
print("Accuracy :", accuracy_score(y_test_pca, y_pred_pca))
print("Precision:", precision_score(y_test_pca, y_pred_pca))
print("Recall   :", recall_score(y_test_pca, y_pred_pca))
print("F1-score :", f1_score(y_test_pca, y_pred_pca))
print("Confusion Matrix:\n", confusion_matrix(y_test_pca, y_pred_pca))

#Feature Importance and Comparison
print("\nFeature importances (Baseline DT):")
for col, val in zip(df.drop("Result", axis=1).columns, dt.feature_importances_):
    print(f"{col}: {val:.4f}")

print("\nPCA explained variance ratio:")
print(pca.explained_variance_ratio_)

